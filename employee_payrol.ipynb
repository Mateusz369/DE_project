{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6451e4-9337-46cd-aba6-7b5b7beab378",
   "metadata": {},
   "source": [
    "# 02. TLC Employees Payroll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f9d32-e95f-45ee-9102-131ac20f40de",
   "metadata": {},
   "source": [
    "Dataset used in this project consist TLC employees (TAXI & LIMOUSINE COMMISSION) with remunerations per fiscal year. After a simple extract from the API and load to Postgres, data is modeled in Postgres. The idea behind it is to compress the data (in a run-length encoding style), keep the data ordered (using an array for changing dimensions, which keeps the order after exploding) and to enable historical analysis without shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315de079-b3ed-42dc-8f91-a20fe77b73da",
   "metadata": {},
   "source": [
    "### Getting data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59911595-96e3-46b1-a44f-1deda6cc2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "URL = \"https://data.cityofnewyork.us/resource/k397-673e.json\"\n",
    "\n",
    "LIMIT = 100000 \n",
    "OFFSET = 0\n",
    "all_rows = []\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"$limit\": LIMIT,\n",
    "        \"$offset\": OFFSET\n",
    "    }\n",
    "\n",
    "    response = requests.get(URL, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    batch = response.json()\n",
    "\n",
    "    if not batch:\n",
    "        break\n",
    "\n",
    "    all_rows.extend(batch)\n",
    "    OFFSET += LIMIT\n",
    "\n",
    "    time.sleep(0.2) \n",
    "\n",
    "\n",
    "fieldnames = set()\n",
    "for row in all_rows:\n",
    "    fieldnames.update(row.keys())\n",
    "\n",
    "fieldnames = sorted(fieldnames)\n",
    "\n",
    "with open(\"nyc_payroll.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7cd60d-5e19-48a3-b43a-67cc903d9391",
   "metadata": {},
   "source": [
    "### Postgres upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f38a132-d1a7-4caf-9524-133a8bcc555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "POSTGRES_USER = \"postgres\"\n",
    "POSTGRES_PASSWORD = \"postgres\"\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "POSTGRES_PORT = \"5433\"    \n",
    "POSTGRES_DB = \"postgres\"\n",
    "\n",
    "engine_url = f\"postgresql+psycopg://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "engine = create_engine(engine_url)\n",
    "\n",
    "csv_file = r\"\\nyc_payroll.csv\"\n",
    "\n",
    "table_name = \"nyc_payroll\"\n",
    "\n",
    "print(\"Wczytywanie pliku CSV\")\n",
    "df = pd.read_csv(csv_file, dtype=str, delimiter=';')\n",
    "\n",
    "print(\"Zapisywanie do Postgresa\")\n",
    "df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "\n",
    "print(f\"Dane z pliku CSV zosta≈Çy dopisane do tabeli {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911845c-8f86-42e1-9098-f042995cf106",
   "metadata": {},
   "source": [
    "### Postgres data modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29593ed9-7884-4840-9f01-9f8831c1ff4a",
   "metadata": {},
   "source": [
    "First, we create a type for all numeric values that an employee has. They will be stored in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cd10e-d9d5-442a-8759-f991bbccfa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TYPE stats AS(\n",
    "fiscal_year INT,\n",
    "base_salary FLOAT,\n",
    "regular_hours FLOAT,\n",
    "regular_gross_paid FLOAT,\n",
    "ot_hours FLOAT,\n",
    "total_ot_paid FLOAT,\n",
    "total_other_pay FLOAT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772019c8-57d6-4236-934d-149806861b6c",
   "metadata": {},
   "source": [
    "Type is then used in new table, where we input our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f19ae0-19d9-4a4e-b744-43af148aff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE nyc_payroll_tlc (\n",
    "first_name TEXT,\n",
    "last_name TEXT,\n",
    "start_date DATE,\n",
    "title_description TEXT,\n",
    "pay_basis TEXT,\n",
    "stats stats[],\n",
    "years_since_last_employed INTEGER,\n",
    "current_FY INT,\n",
    "PRIMARY KEY (first_name, last_name, current_FY)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42496c-881a-42d4-a6da-141cf6828b7f",
   "metadata": {},
   "source": [
    "Now we run cumulative query. It has to be executed fully, for all the years one by one, but it's splitted here for readability\n",
    "\n",
    "<span style=\"color: blue;\">---FULL QUERY STARTS HERE</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932105a-2167-4817-9d00-059b6c206ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT INTO nyc_payroll_tlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a7eba-0ffe-40c0-bec4-93b9884f9d13",
   "metadata": {},
   "source": [
    "'yesteday' is is based on the data added previously to the new 'nyc_payroll_tlc ' table, so in the first run, it's empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506746b-4d92-4b8f-9136-f0e2da2208c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH yesterday AS (\n",
    "SELECT *\n",
    "FROM nyc_payroll_tlc\n",
    "WHERE current_FY = '2013' #increase by 1 in each iteration\n",
    "),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466ddb8-de24-4f26-b3cc-29ba19ef9135",
   "metadata": {},
   "source": [
    "'today' is based on the original tabel that was uploaded to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f812d1-62e6-497a-a26e-31a5fb8e2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "today AS(\n",
    "SELECT *\n",
    "FROM nyc_payroll\n",
    "WHERE agency_name = 'TAXI & LIMOUSINE COMMISSION'\n",
    "AND fiscal_year = '2014' #increase by 1 in each iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b22c4-1891-447a-a4fa-95b188c37e72",
   "metadata": {},
   "source": [
    "Now, we define the data. If there is a data today, we take it, otherwise we take yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163fcd60-e672-4d8d-a663-c16f8a21ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "COALESCE(t.first_name, y.first_name) AS first_name,\n",
    "COALESCE(t.last_name, y.last_name) AS last_name,\n",
    "COALESCE(CAST(t.agency_start_date AS DATE), y.start_date) AS start_date,\n",
    "COALESCE(t.title_description, y.title_description) AS title_description,\n",
    "COALESCE(t.pay_basis, y.pay_basis) AS pay_basis,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2d53e-d2d8-4327-ba2d-d331bdc3e4ce",
   "metadata": {},
   "source": [
    "Here is the crucial part. There are 3 scenarios:\n",
    "- if yesterday's stats are NULL, then we take today (meaning there is no history of a record, it's new)\n",
    "- if today's stats are there (today is NOT NULL), then we take today but concat it with yesterday, meaning what's already in the table. It enables to keep the history in the same row\n",
    "- otherwise, so if today is NULL (there are no new records) we keep tracking yesterday's historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2353cd-9cbf-458b-9efd-3f50b9cb8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE \n",
    "\tWHEN y.stats IS NULL THEN ARRAY[ROW(\n",
    "t.fiscal_year,\n",
    "t.base_salary,\n",
    "t.regular_hours,\n",
    "t.regular_gross_paid,\n",
    "t.ot_hours,\n",
    "t.total_ot_paid,\n",
    "t.total_other_pay\n",
    ")::stats]\n",
    "\tWHEN t.fiscal_year IS NOT NULL THEN y.stats || ARRAY[ROW(\n",
    "t.fiscal_year,\n",
    "t.base_salary,\n",
    "t.regular_hours,\n",
    "t.regular_gross_paid,\n",
    "t.ot_hours,\n",
    "t.total_ot_paid,\n",
    "t.total_other_pay\n",
    ")::stats]\n",
    "\tELSE y.stats\n",
    "\tEND AS stats,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68811096-7ab4-40e3-b9d0-1662f33a92c4",
   "metadata": {},
   "source": [
    "Additionally, we track number of years since the last record occured and we add a year of the latest incremental load of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7ab81-bdc5-410e-a6d9-92d3cc3056e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE \n",
    "\tWHEN t.fiscal_year IS NOT NULL THEN 0\n",
    "\tELSE y.years_since_last_employed + 1\n",
    "\tEND AS years_since_last_employed,\n",
    "COALESCE(t.fiscal_year, y.current_FY + 1) AS current_FY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0ac71-c4b8-4b68-a6b0-59c34067bb10",
   "metadata": {},
   "source": [
    "Finally, we join both tables based on first and last name. Wheater there is a value in one of the tables, we will get all data (because of FULL JOIN) without extra columns (because of previous COALESCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37152ed8-7c84-42db-a4f6-a2b012d68a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM today t FULL OUTER JOIN yesterday y\n",
    "ON t.first_name = y.first_name\n",
    "AND t.last_name = y.last_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019eb766-2e18-4508-a99c-c3afda8949dc",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">---FULL QUERY ENDS HERE</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05a840-1f6b-4859-9bf1-22548a92115a",
   "metadata": {},
   "source": [
    "Now we can select * from the new table, based on the last added year (it will hold all the previous values if they exist) and some random name as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e7b03-a753-438f-bb82-d008b24146bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM nyc_payroll_tlc\n",
    "WHERE last_name = 'AFRIN'\n",
    "AND first_name = 'SABIHA'\n",
    "AND current_FY = 2025\n",
    "ORDER BY first_name, last_name, current_FY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9aeceb-73f1-41e5-a59b-5309a8f8d424",
   "metadata": {},
   "source": [
    "We can see the 'stats' are starting in 2015 and ending in 2022 (based on 'years_since_last_employed' column). That is the cumulative table design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202c4ea-be34-4752-b579-ddc9a9234f86",
   "metadata": {},
   "source": [
    "![](images/03_payroll.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869762bc-71ef-4b37-8f7e-05f28cac412c",
   "metadata": {},
   "source": [
    "If needed, the table could be UNNESTED later, showing all the stats in separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a70f8-957a-4db9-bc16-49a2121d4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH unnested  AS(\n",
    "\tSELECT first_name, last_name, title_description,\n",
    "\t\tUNNEST(stats)::stats AS stats\n",
    "\t\tFROM nyc_payroll_tlc\n",
    "\t\tWHERE current_FY = 2025\n",
    "\t\tAND last_name = 'ABRAMOVICH'\n",
    "\t\tAND first_name = 'MICHAEL'\n",
    "\t\t)\n",
    "\t\t\n",
    "SELECT first_name, last_name,\n",
    "\t(stats::stats).* \n",
    "FROM unnested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44239b-fe9d-48b7-b721-e4cf8caf6b41",
   "metadata": {},
   "source": [
    "![](images/04_payroll.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9ae0a-affa-47f3-a201-cca863aa192b",
   "metadata": {},
   "source": [
    "If we want to UNNEST everything, the data will keep the order based on names and fiscal_year, which helps avoid re-sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f4804-c02f-48d4-bda2-0c72a0924f1d",
   "metadata": {},
   "source": [
    "![](images/05_payroll.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
